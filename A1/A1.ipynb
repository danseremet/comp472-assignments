{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_1 = pd.read_csv(\"data/info_1.csv\", header=None) \n",
    "info_2 = pd.read_csv(\"data/info_2.csv\", header=None) \n",
    "test_no_label_1 = pd.read_csv(\"data/test_no_label_1.csv\", header=None) \n",
    "test_no_label_2 = pd.read_csv(\"data/test_no_label_2.csv\",header=None) \n",
    "test_with_label_1 = pd.read_csv(\"data/test_with_label_1.csv\", header=None) \n",
    "test_with_label_2 = pd.read_csv(\"data/test_with_label_2.csv\", header=None) \n",
    "train_1 = pd.read_csv(\"data/train_1.csv\", header=None) \n",
    "train_2 = pd.read_csv(\"data/train_2.csv\", header=None) \n",
    "val_1 = pd.read_csv(\"data/val_1.csv\", header=None) \n",
    "val_2 = pd.read_csv(\"data/val_2.csv\", header=None) \n",
    "sample_submission = pd.read_csv(\"data/sample_submission.csv\", header=None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition the data sets 1 & 2 into train, val and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data set 1\n",
    "X_train_1 = train_1.iloc[:, 0:1024].to_numpy()\n",
    "Y_train_1 = train_1.iloc[:, 1024:1025].to_numpy().ravel()\n",
    "\n",
    "X_val_1 = val_1.iloc[:, 0:1024].to_numpy()\n",
    "Y_val_1 = val_1.iloc[:, 1024:1025].to_numpy().ravel()\n",
    "\n",
    "X_test_1 = test_with_label_1.iloc[:, 0:1024].to_numpy()\n",
    "Y_test_1 = test_with_label_1.iloc[:, 1024:1025].to_numpy().ravel()\n",
    "\n",
    "# Data set 2\n",
    "X_train_2 = train_2.iloc[:, 0:1024].to_numpy()\n",
    "Y_train_2 = train_2.iloc[:, 1024:1025].to_numpy().ravel()\n",
    "\n",
    "X_val_2 = val_2.iloc[:, 0:1024].to_numpy()\n",
    "Y_val_2 = val_2.iloc[:, 1024:1025].to_numpy().ravel()\n",
    "\n",
    "X_test_2 = test_with_label_2.iloc[:, 0:1024].to_numpy()\n",
    "Y_test_2 = test_with_label_2.iloc[:, 1024:1025].to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "DataSet_Y_1 = np.concatenate((Y_train_1, Y_val_1, Y_test_1), axis=0) \n",
    "DataSet_Y_2 = np.concatenate((Y_train_2, Y_val_2, Y_test_2), axis=0) \n",
    "DataSet_Count_1 = np.bincount(DataSet_Y_1)\n",
    "DataSet_Count_2 = np.bincount(DataSet_Y_2)\n",
    "\n",
    "# DS1\n",
    "labels_1 =  [chr(x) for x in range(ord('A'), ord('Z') + 1)]\n",
    "labels_value_1 = np.arange(len(labels_1))\n",
    "\n",
    "plt.bar(labels_value_1, DataSet_Count_1, align='center', alpha=0.5)\n",
    "plt.xticks(labels_value_1, labels_1)\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Letters in Data Set 1')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# DS2\n",
    "labels_2 =  ['π', 'α', 'β', 'σ', 'γ', 'δ', 'λ', 'ω', 'μ', 'ξ']\n",
    "labels_value_2 = np.arange(len(labels_2))\n",
    "\n",
    "plt.bar(labels_value_2, DataSet_Count_2, align='center', alpha=0.5)\n",
    "plt.xticks(labels_value_2, labels_2)\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Greek Letters in Data Set 2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of datasets\n",
    "\n",
    "#### For Data Set 1 (Letters from A to Z)\n",
    "The dataset 1 is mostly evenly distributed. One thing that could make the models less performant is the big amount of classes in this set (26 in this case). So the models will require to make a decision of classifying between 26 classes. If we were to make a random choice, each class would have a 1/26 probability of occurrence. So the models have less chance of being correct by leveraging luck.\n",
    "\n",
    "#### For Data Set 2 (10 Greek Letters)\n",
    "The dataset 2 is not evenly distributed, this could lead to some some letters being better classified than other letters that occur much less.\n",
    "Another thing is that because there are less classes than in the first data set, this dataset has 1/10 chance of guessing the correct class by a random guess. So this dataset provides better odds to the same model than the previous dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Imports for GNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# DS1\n",
    "trained_model_1 = gnb.fit(X_train_1, Y_train_1)\n",
    "Y_pred_1 = trained_model_1.predict(X_test_1)\n",
    "\n",
    "# DS2\n",
    "trained_model_2 = gnb.fit(X_train_2, Y_train_2)\n",
    "Y_pred_2 = trained_model_2.predict(X_test_2)\n",
    "\n",
    "# Outputs\n",
    "GNB_DS1 = pd.DataFrame(data=Y_pred_1)\n",
    "GNB_DS1.index = GNB_DS1.index + 1\n",
    "GNB_DS1.to_csv(\"output_files/GNB-DS1.csv\", header=None)\n",
    "\n",
    "GNB_DS2 = pd.DataFrame(data=Y_pred_2)\n",
    "GNB_DS2.index = GNB_DS2.index + 1\n",
    "GNB_DS2.to_csv(\"output_files/GNB-DS2.csv\", header=None)\n",
    "\n",
    "f_GNB_DS1 = open(\"output_files/GNB-DS1.csv\", \"a\")\n",
    "conf_1 = confusion_matrix(Y_test_1, Y_pred_1)\n",
    "report_1 = classification_report(Y_test_1, Y_pred_1)\n",
    "f_GNB_DS1.write(\"\\nConfusion Matrix:\\n\\n\")\n",
    "f_GNB_DS1.write(str(conf_1))\n",
    "f_GNB_DS1.write(\"\\n\\nClassification Report:\\n\\n\")\n",
    "f_GNB_DS1.write(str(report_1))\n",
    "f_GNB_DS1.close()\n",
    "\n",
    "f_GNB_DS2 = open(\"output_files/GNB-DS2.csv\", \"a\")\n",
    "conf_2 = confusion_matrix(Y_test_2, Y_pred_2)\n",
    "report_2 = classification_report(Y_test_2, Y_pred_2)\n",
    "f_GNB_DS2.write(\"\\nConfusion Matrix:\\n\\n\")\n",
    "f_GNB_DS2.write(str(conf_2))\n",
    "f_GNB_DS2.write(\"\\n\\nClassification Report:\\n\\n\")\n",
    "f_GNB_DS2.write(str(report_2))\n",
    "f_GNB_DS2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "- The warning is generated (from the first dataset) because the letter E corresponding to value 4 \n",
    "is never predicted by our model when it should have been predicted 2 times\n",
    "in the Y_test_1.\n",
    "- This leads to a denominator of 0 in the precision calculation and the same for the F1 measure therefore the report defaults these values to 0.0 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base-DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Imports for DT\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "base_dt = DecisionTreeClassifier(criterion=\"entropy\", random_state=0)\n",
    "\n",
    "# DS1\n",
    "trained_model_1 = base_dt.fit(X_train_1, Y_train_1)\n",
    "Y_pred_1 = trained_model_1.predict(X_test_1)\n",
    "\n",
    "# DS2\n",
    "trained_model_2 = base_dt.fit(X_train_2, Y_train_2)\n",
    "Y_pred_2 = trained_model_2.predict(X_test_2)\n",
    "\n",
    "# Outputs\n",
    "Base_DT_DS1 = pd.DataFrame(data=Y_pred_1)\n",
    "Base_DT_DS1.index = Base_DT_DS1.index + 1\n",
    "Base_DT_DS1.to_csv(\"output_files/Base-DT-DS1.csv\", header=None)\n",
    "\n",
    "Base_DT_DS2 = pd.DataFrame(data=Y_pred_2)\n",
    "Base_DT_DS2.index = Base_DT_DS2.index + 1\n",
    "Base_DT_DS2.to_csv(\"output_files/Base-DT-DS2.csv\", header=None)\n",
    "\n",
    "f_Base_DT_DS1 = open(\"output_files/Base-DT-DS1.csv\", \"a\")\n",
    "conf_1 = confusion_matrix(Y_test_1, Y_pred_1)\n",
    "report_1 = classification_report(Y_test_1, Y_pred_1)\n",
    "f_Base_DT_DS1.write(\"\\nConfusion Matrix:\\n\\n\")\n",
    "f_Base_DT_DS1.write(str(conf_1))\n",
    "f_Base_DT_DS1.write(\"\\n\\nClassification Report:\\n\\n\")\n",
    "f_Base_DT_DS1.write(str(report_1))\n",
    "f_Base_DT_DS1.close()\n",
    "\n",
    "f_Base_DT_DS2 = open(\"output_files/Base-DT-DS2.csv\", \"a\")\n",
    "conf_2 = confusion_matrix(Y_test_2, Y_pred_2)\n",
    "report_2 = classification_report(Y_test_2, Y_pred_2)\n",
    "f_Base_DT_DS2.write(\"\\nConfusion Matrix:\\n\\n\")\n",
    "f_Base_DT_DS2.write(str(conf_2))\n",
    "f_Base_DT_DS2.write(\"\\n\\nClassification Report:\\n\\n\")\n",
    "f_Base_DT_DS2.write(str(report_2))\n",
    "f_Base_DT_DS2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best-DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for DT\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'criterion':['gini', 'entropy'], \n",
    "    'max_depth':[10, None],\n",
    "    'min_samples_split':[1, 2, 3, 4],\n",
    "    'min_impurity_decrease':[0.0, 0.5],\n",
    "    'class_weight':[None, 'balanced'],\n",
    "}\n",
    "# DecisionTreeClassifier\n",
    "best_dt = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=parameters, n_jobs=-1)\n",
    "\n",
    "# DS1\n",
    "trained_model_1 = best_dt.fit(X_train_1, Y_train_1)\n",
    "Y_pred_1 = trained_model_1.predict(X_test_1)\n",
    "\n",
    "# DS2\n",
    "trained_model_2 = best_dt.fit(X_train_2, Y_train_2)\n",
    "Y_pred_2 = trained_model_2.predict(X_test_2)\n",
    "\n",
    "# Outputs\n",
    "Best_DT_DS1 = pd.DataFrame(data=Y_pred_1)\n",
    "Best_DT_DS1.index = Best_DT_DS1.index + 1\n",
    "Best_DT_DS1.to_csv(\"output_files/Best-DT-DS1.csv\", header=None)\n",
    "\n",
    "Best_DT_DS2 = pd.DataFrame(data=Y_pred_2)\n",
    "Best_DT_DS2.index = Best_DT_DS2.index + 1\n",
    "Best_DT_DS2.to_csv(\"output_files/Best-DT-DS2.csv\", header=None)\n",
    "\n",
    "f_Best_DT_DS1 = open(\"output_files/Best-DT-DS1.csv\", \"a\")\n",
    "conf_1 = confusion_matrix(Y_test_1, Y_pred_1)\n",
    "report_1 = classification_report(Y_test_1, Y_pred_1)\n",
    "f_Best_DT_DS1.write(\"\\nConfusion Matrix:\\n\\n\")\n",
    "f_Best_DT_DS1.write(str(conf_1))\n",
    "f_Best_DT_DS1.write(\"\\n\\nClassification Report:\\n\\n\")\n",
    "f_Best_DT_DS1.write(str(report_1))\n",
    "f_Best_DT_DS1.close()\n",
    "\n",
    "f_Best_DT_DS2 = open(\"output_files/Best-DT-DS2.csv\", \"a\")\n",
    "conf_2 = confusion_matrix(Y_test_2, Y_pred_2)\n",
    "report_2 = classification_report(Y_test_2, Y_pred_2)\n",
    "f_Best_DT_DS2.write(\"\\nConfusion Matrix:\\n\\n\")\n",
    "f_Best_DT_DS2.write(str(conf_2))\n",
    "f_Best_DT_DS2.write(\"\\n\\nClassification Report:\\n\\n\")\n",
    "f_Best_DT_DS2.write(str(report_2))\n",
    "f_Best_DT_DS2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': None, 'min_impurity_decrease': 0.0, 'min_samples_split': 2}\n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': None, 'min_impurity_decrease': 0.0, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters:\")\n",
    "print(trained_model_1.best_params_)\n",
    "print(trained_model_2.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for Perceptron\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "perceptron = Perceptron()\n",
    "\n",
    "# DS1\n",
    "trained_model_1 = perceptron.fit(X_train_1, Y_train_1)\n",
    "Y_pred_1 = trained_model_1.predict(X_test_1)\n",
    "\n",
    "# DS2\n",
    "trained_model_2 = perceptron.fit(X_train_2, Y_train_2)\n",
    "Y_pred_2 = trained_model_2.predict(X_test_2)\n",
    "\n",
    "# Outputs\n",
    "Perceptron_DS1 = pd.DataFrame(data=Y_pred_1)\n",
    "Perceptron_DS1.index = Perceptron_DS1.index + 1\n",
    "Perceptron_DS1.to_csv(\"output_files/PER-DS1.csv\", header=None)\n",
    "\n",
    "Perceptron_DS2 = pd.DataFrame(data=Y_pred_2)\n",
    "Perceptron_DS2.index = Perceptron_DS2.index + 1\n",
    "Perceptron_DS2.to_csv(\"output_files/PER-DS2.csv\", header=None)\n",
    "\n",
    "f_Perceptron_DS1 = open(\"output_files/PER-DS1.csv\", \"a\")\n",
    "conf_1 = confusion_matrix(Y_test_1, Y_pred_1)\n",
    "report_1 = classification_report(Y_test_1, Y_pred_1)\n",
    "f_Perceptron_DS1.write(\"\\nConfusion Matrix:\\n\\n\")\n",
    "f_Perceptron_DS1.write(str(conf_1))\n",
    "f_Perceptron_DS1.write(\"\\n\\nClassification Report:\\n\\n\")\n",
    "f_Perceptron_DS1.write(str(report_1))\n",
    "f_Perceptron_DS1.close()\n",
    "\n",
    "f_Perceptron_DS2 = open(\"output_files/PER-DS2.csv\", \"a\")\n",
    "conf_2 = confusion_matrix(Y_test_2, Y_pred_2)\n",
    "report_2 = classification_report(Y_test_2, Y_pred_2)\n",
    "f_Perceptron_DS2.write(\"\\nConfusion Matrix:\\n\\n\")\n",
    "f_Perceptron_DS2.write(str(conf_2))\n",
    "f_Perceptron_DS2.write(\"\\n\\nClassification Report:\\n\\n\")\n",
    "f_Perceptron_DS2.write(str(report_2))\n",
    "f_Perceptron_DS2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base-MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Imports for MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(activation='logistic', solver='sgd')\n",
    "\n",
    "# DS1\n",
    "trained_model_1 = mlp.fit(X_train_1, Y_train_1)\n",
    "Y_pred_1 = trained_model_1.predict(X_test_1)\n",
    "\n",
    "# DS2\n",
    "trained_model_2 = mlp.fit(X_train_2, Y_train_2)\n",
    "Y_pred_2 = trained_model_2.predict(X_test_2)\n",
    "\n",
    "# Outputs\n",
    "MLP_DS1 = pd.DataFrame(data=Y_pred_1)\n",
    "MLP_DS1.index = MLP_DS1.index + 1\n",
    "MLP_DS1.to_csv(\"output_files/Base-MLP-DS1.csv\", header=None)\n",
    "\n",
    "MLP_DS2 = pd.DataFrame(data=Y_pred_2)\n",
    "MLP_DS2.index = MLP_DS2.index + 1\n",
    "MLP_DS2.to_csv(\"output_files/Base-MLP-DS2.csv\", header=None)\n",
    "\n",
    "f_MLP_DS1 = open(\"output_files/Base-MLP-DS1.csv\", \"a\")\n",
    "conf_1 = confusion_matrix(Y_test_1, Y_pred_1)\n",
    "report_1 = classification_report(Y_test_1, Y_pred_1)\n",
    "f_MLP_DS1.write(\"\\nConfusion Matrix:\\n\\n\")\n",
    "f_MLP_DS1.write(str(conf_1))\n",
    "f_MLP_DS1.write(\"\\n\\nClassification Report:\\n\\n\")\n",
    "f_MLP_DS1.write(str(report_1))\n",
    "f_MLP_DS1.close()\n",
    "\n",
    "f_MLP_DS2 = open(\"output_files/Base-MLP-DS2.csv\", \"a\")\n",
    "conf_2 = confusion_matrix(Y_test_2, Y_pred_2)\n",
    "report_2 = classification_report(Y_test_2, Y_pred_2)\n",
    "f_MLP_DS2.write(\"\\nConfusion Matrix:\\n\\n\")\n",
    "f_MLP_DS2.write(str(conf_2))\n",
    "f_MLP_DS2.write(\"\\n\\nClassification Report:\\n\\n\")\n",
    "f_MLP_DS2.write(str(report_2))\n",
    "f_MLP_DS2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best-MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Imports for MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "parameters = {\n",
    "    'activation':['logistic', 'tanh', 'relu', 'identity'], \n",
    "    'hidden_layer_sizes':[(30, 50), (10, 10, 10)],\n",
    "    'solver':['adam', 'sgd'],\n",
    "}\n",
    "# Best MLP\n",
    "mlp = GridSearchCV(estimator=MLPClassifier(), param_grid=parameters, n_jobs=-1)\n",
    "\n",
    "# DS1\n",
    "trained_model_1 = mlp.fit(X_train_1, Y_train_1)\n",
    "Y_pred_1 = trained_model_1.predict(X_test_1)\n",
    "\n",
    "# DS2\n",
    "trained_model_2 = mlp.fit(X_train_2, Y_train_2)\n",
    "Y_pred_2 = trained_model_2.predict(X_test_2)\n",
    "\n",
    "# Outputs\n",
    "MLP_DS1 = pd.DataFrame(data=Y_pred_1)\n",
    "MLP_DS1.index = MLP_DS1.index + 1\n",
    "MLP_DS1.to_csv(\"output_files/Best-MLP-DS1.csv\", header=None)\n",
    "\n",
    "MLP_DS2 = pd.DataFrame(data=Y_pred_2)\n",
    "MLP_DS2.index = MLP_DS2.index + 1\n",
    "MLP_DS2.to_csv(\"output_files/Best-MLP-DS2.csv\", header=None)\n",
    "\n",
    "f_MLP_DS1 = open(\"output_files/Best-MLP-DS1.csv\", \"a\")\n",
    "conf_1 = confusion_matrix(Y_test_1, Y_pred_1)\n",
    "report_1 = classification_report(Y_test_1, Y_pred_1)\n",
    "f_MLP_DS1.write(\"\\nConfusion Matrix:\\n\\n\")\n",
    "f_MLP_DS1.write(str(conf_1))\n",
    "f_MLP_DS1.write(\"\\n\\nClassification Report:\\n\\n\")\n",
    "f_MLP_DS1.write(str(report_1))\n",
    "f_MLP_DS1.close()\n",
    "\n",
    "f_MLP_DS2 = open(\"output_files/Best-MLP-DS2.csv\", \"a\")\n",
    "conf_2 = confusion_matrix(Y_test_2, Y_pred_2)\n",
    "report_2 = classification_report(Y_test_2, Y_pred_2)\n",
    "f_MLP_DS2.write(\"\\nConfusion Matrix:\\n\\n\")\n",
    "f_MLP_DS2.write(str(conf_2))\n",
    "f_MLP_DS2.write(\"\\n\\nClassification Report:\\n\\n\")\n",
    "f_MLP_DS2.write(str(report_2))\n",
    "f_MLP_DS2.close()\n",
    "\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      "{'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'sgd'}\n",
      "{'activation': 'tanh', 'hidden_layer_sizes': (30, 50), 'solver': 'sgd'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best hyperparameters:\")\n",
    "print(trained_model_1.best_params_)\n",
    "print(trained_model_2.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregated results of all models and all data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy [0], \n",
    "# precision_macro_avg [1], precision_weighted_avg[2],\n",
    "# recall_macro_avg[3], recall_weighted_avg[4], \n",
    "# f1_macro_avg[5], f1_weighted_avg[6]\n",
    "\n",
    "metrics = {\n",
    "    'DS1': {          #   acc  m_pr  w_pr   m_r   w_r  m_f1  w_f1\n",
    "        'GNB-DS1':      [0.69, 0.74, 0.75, 0.69, 0.69, 0.68, 0.69],\n",
    "        'Base-DT-DS1':  [0.49, 0.49, 0.51, 0.47, 0.49, 0.45, 0.47],\n",
    "        'Best-DT-DS1':  [0.46, 0.45, 0.48, 0.45, 0.46, 0.42, 0.45],\n",
    "        'PER-DS1':      [0.78, 0.79, 0.80, 0.76, 0.78, 0.76, 0.77],\n",
    "        'Base-MLP-DS1': [0.45, 0.32, 0.36, 0.40, 0.45, 0.32, 0.36],\n",
    "        'Best-MLP-DS1': [0.81, 0.85, 0.85, 0.81, 0.81, 0.80, 0.80]\n",
    "    },\n",
    "    'DS2': {\n",
    "        'GNB-DS2':      [0.67, 0.64, 0.75, 0.68, 0.67, 0.60, 0.68],\n",
    "        'Base-DT-DS2':  [0.78, 0.73, 0.78, 0.69, 0.78, 0.71, 0.78],    \n",
    "        'Best-DT-DS2':  [0.74, 0.69, 0.74, 0.68, 0.74, 0.68, 0.74],\n",
    "        'PER-DS2':      [0.84, 0.83, 0.84, 0.78, 0.84, 0.79, 0.83],\n",
    "        'Base-MLP-DS2': [0.83, 0.84, 0.83, 0.73, 0.83, 0.76, 0.82],\n",
    "        'Best-MLP-DS2': [0.87, 0.87, 0.87, 0.81, 0.87, 0.83, 0.87]        \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "- Concerning accuracy, macro precision, weighted precision, macro recall, weighted precision, macro f1 and weighted f1, Best-MLP is the best model for both of these data sets. It was expected, since neural networks are usually better performing than other models (in general).\n",
    "\n",
    "- Using the data set 1, the models have worse performance than with data set 2 (exception is with GNB: Gaussian Naive Bayes). The main reason for this is that data set 1 has more classes than data set 2 so it is harder to correctly predict the right outcome.\n",
    "\n",
    "- For data set 1, the models Base-DT, Best-DT and Base-MLP have performed significantly worse than for data set 2. \n",
    "\n",
    "- For both data sets, the Best-DT performs worse than the Base-DT. This could be caused by the the fact that our model trained itself by doing k-fold validation and picking the best hyperparameters for the validations sets (from the training set), but it actually resulted in worse performance when tested against the test set.\n",
    "\n",
    "- To properly evaluate the models, it will be better to use the weighted averages when it is trained against data set 1 because the classes are not evenly distributed (observed from our prior analysis of the data sets).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
