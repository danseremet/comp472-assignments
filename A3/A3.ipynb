{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load covid_training\n",
    "covid_training = pd.read_csv(\"data/covid_training.tsv\", delimiter=\"\\t\") \n",
    "# Load covid_test_public\n",
    "covid_test_public = pd.read_csv(\"data/covid_test_public.tsv\", header=None, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set 399 tweets\n",
    "X_covid_training = covid_training.iloc[:, 1].to_numpy()\n",
    "Y_covid_training = covid_training.iloc[:, 2].to_numpy()\n",
    "\n",
    "# Test set 55 tweet\n",
    "X_covid_test_public = covid_test_public.iloc[:, 1].to_numpy()\n",
    "Y_covid_test_public = covid_test_public.iloc[:, 2].to_numpy()\n",
    "\n",
    "X_covid_test_public_tweet_ids = covid_test_public.iloc[:, 0].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting tokens in OV and FV\n",
    "\n",
    "total_count = Counter()\n",
    "for tweet in X_covid_training:\n",
    "    tokens = tweet.lower().split()\n",
    "    total_count += Counter(tokens)\n",
    "\n",
    "total_count = total_count.most_common()\n",
    "words = [i[0] for i in total_count]\n",
    "\n",
    "def two_or_more_words(word_count):\n",
    "    return True if word_count[1] >= 2 else False\n",
    "\n",
    "total_count_fv = list(filter(two_or_more_words, total_count))\n",
    "words_fv = [i[0] for i in total_count_fv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into 2 classes (yes, no)\n",
    "\n",
    "X_covid_training\n",
    "Y_covid_training\n",
    "\n",
    "X_covid_training_yes = []\n",
    "X_covid_training_no = []\n",
    "\n",
    "for i, c in enumerate(Y_covid_training):\n",
    "    if c == 'yes':\n",
    "        X_covid_training_yes.append(X_covid_training[i])\n",
    "    elif c == 'no':\n",
    "        X_covid_training_no.append(X_covid_training[i])\n",
    "\n",
    "P_prior_yes = len(X_covid_training_yes) / (len(X_covid_training_yes) + len(X_covid_training_no))\n",
    "P_prior_no = len(X_covid_training_no) / (len(X_covid_training_yes) + len(X_covid_training_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yes\n",
    "X_covid_training_tokens_yes = np.empty((0,0))\n",
    "\n",
    "total_count_yes = Counter()\n",
    "for tweet in X_covid_training_yes:\n",
    "    tokens = tweet.lower().split()\n",
    "    total_count_yes += Counter(tokens)\n",
    "    X_covid_training_tokens_yes = np.append(X_covid_training_tokens_yes, np.array(tokens))\n",
    "\n",
    "total_count_yes = total_count_yes.most_common()\n",
    "words_yes = [i[0] for i in total_count_yes]\n",
    "vocab_yes_len = len(X_covid_training_tokens_yes)\n",
    "frequencies_yes = [i[1] for i in total_count_yes]\n",
    "\n",
    "\n",
    "def two_or_more(count):\n",
    "    return True if count >= 2 else False\n",
    "\n",
    "frequencies_yes_fv = list(filter(two_or_more, frequencies_yes))\n",
    "words_yes_fv = words_yes[0:len(frequencies_yes_fv)]\n",
    "\n",
    "def filter_for_fv_yes(token):\n",
    "    return True if token in words_yes_fv else False\n",
    "    \n",
    "X_covid_training_tokens_yes_fv = list(filter(filter_for_fv_yes, X_covid_training_tokens_yes))\n",
    "vocab_yes_len_fv = len(X_covid_training_tokens_yes_fv)\n",
    "\n",
    "# no\n",
    "X_covid_training_tokens_no = np.empty((0,0))\n",
    "\n",
    "total_count_no = Counter()\n",
    "for tweet in X_covid_training_no:\n",
    "    tokens = tweet.lower().split()\n",
    "    total_count_no += Counter(tokens)\n",
    "    X_covid_training_tokens_no = np.append(X_covid_training_tokens_no, np.array(tokens))\n",
    "\n",
    "total_count_no = total_count_no.most_common()\n",
    "words_no = [i[0] for i in total_count_no]\n",
    "vocab_no_len = len(X_covid_training_tokens_no)\n",
    "frequencies_no = [i[1] for i in total_count_no]\n",
    "\n",
    "frequencies_no_fv = list(filter(two_or_more, frequencies_no))\n",
    "words_no_fv = words_no[0:len(frequencies_no_fv)]\n",
    "\n",
    "def filter_for_fv_no(token):\n",
    "    return True if token in words_no_fv else False\n",
    "    \n",
    "X_covid_training_tokens_no_fv = list(filter(filter_for_fv_no, X_covid_training_tokens_no))\n",
    "vocab_no_len_fv = len(X_covid_training_tokens_no_fv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing conditional probabilities\n",
    "P_cond_yes = []\n",
    "P_cond_no = []\n",
    "delta = 0.01\n",
    "vocab_size = len(words)\n",
    "for word in total_count:\n",
    "    if word[0] in words_yes:\n",
    "#         print(f\"{words_yes.index(word[0])} {frequencies_yes[words_yes.index(word[0])]} {frequencies_yes[words_yes.index(word[0])] / vocab_yes_len}\")\n",
    "        prob = (frequencies_yes[words_yes.index(word[0])] + delta) / (vocab_yes_len + vocab_size * delta)\n",
    "        prob = math.log10(prob)\n",
    "        P_cond_yes.append(prob)\n",
    "    else:\n",
    "        prob = delta / (vocab_yes_len + vocab_size * delta)\n",
    "        prob = math.log10(prob)\n",
    "        P_cond_yes.append(prob)\n",
    "    if word[0] in words_no:\n",
    "        prob = (frequencies_no[words_no.index(word[0])] + delta) / (vocab_no_len + vocab_size * delta)\n",
    "        prob = math.log10(prob)\n",
    "        P_cond_no.append(prob)\n",
    "    else:\n",
    "        prob = delta / (vocab_no_len + vocab_size * delta)\n",
    "        prob = math.log10(prob)\n",
    "        P_cond_no.append(prob)\n",
    "        \n",
    "# Computing conditional probabilities\n",
    "P_cond_yes_fv = []\n",
    "P_cond_no_fv = []\n",
    "delta = 0.01\n",
    "vocab_size_fv = len(words_fv)\n",
    "for word in total_count_fv:\n",
    "    if word[0] in words_yes_fv:\n",
    "#         print(f\"{words_yes.index(word[0])} {frequencies_yes[words_yes.index(word[0])]} {frequencies_yes[words_yes.index(word[0])] / vocab_yes_len}\")\n",
    "        prob = (frequencies_yes_fv[words_yes_fv.index(word[0])] + delta) / (vocab_yes_len_fv + vocab_size_fv * delta)\n",
    "        prob = math.log10(prob)\n",
    "        P_cond_yes_fv.append(prob)\n",
    "    else:\n",
    "        prob = delta / (vocab_yes_len + vocab_size_fv * delta)\n",
    "        prob = math.log10(prob)\n",
    "        P_cond_yes_fv.append(prob)\n",
    "    if word[0] in words_no_fv:\n",
    "        prob = (frequencies_no_fv[words_no_fv.index(word[0])] + delta) / (vocab_no_len_fv + vocab_size_fv * delta)\n",
    "        prob = math.log10(prob)\n",
    "        P_cond_no_fv.append(prob)\n",
    "    else:\n",
    "        prob = delta / (vocab_no_len + vocab_size_fv * delta)\n",
    "        prob = math.log10(prob)\n",
    "        P_cond_no_fv.append(prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Scores for Test set\n",
    "\n",
    "Scores_yes = []\n",
    "Scores_no = []\n",
    "Scores_yes_fv = []\n",
    "Scores_no_fv = []\n",
    "\n",
    "for tweet in X_covid_test_public:\n",
    "    tokens = tweet.lower().split()\n",
    "    Score_yes = P_prior_yes\n",
    "    Score_no = P_prior_no\n",
    "    Score_yes_fv = P_prior_yes\n",
    "    Score_no_fv = P_prior_no\n",
    "    for token in tokens:\n",
    "        if token in words:\n",
    "            prob_yes = P_cond_yes[words.index(token)]\n",
    "            prob_no = P_cond_no[words.index(token)]\n",
    "            Score_yes *= prob\n",
    "            Score_no *= prob\n",
    "        if token in words_fv:\n",
    "            prob_yes = P_cond_yes_fv[words_fv.index(token)]\n",
    "            prob_no = P_cond_no_fv[words_fv.index(token)]\n",
    "            Score_yes_fv *= prob\n",
    "            Score_no_fv *= prob\n",
    "            \n",
    "    Scores_yes.append(Score_yes)\n",
    "    Scores_no.append(Score_no)\n",
    "    Scores_yes_fv.append(Score_yes_fv)\n",
    "    Scores_no_fv.append(Score_no_fv)\n",
    "    \n",
    "    \n",
    "# find yes or no from max score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6087    0.4242    0.5000        33\n",
      "           1     0.4062    0.5909    0.4815        22\n",
      "\n",
      "    accuracy                         0.4909        55\n",
      "   macro avg     0.5075    0.5076    0.4907        55\n",
      "weighted avg     0.5277    0.4909    0.4926        55\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5938    0.5758    0.5846        33\n",
      "           1     0.3913    0.4091    0.4000        22\n",
      "\n",
      "    accuracy                         0.5091        55\n",
      "   macro avg     0.4925    0.4924    0.4923        55\n",
      "weighted avg     0.5128    0.5091    0.5108        55\n",
      "\n",
      "[[14 19]\n",
      " [ 9 13]]\n",
      "0.4909\n",
      "0.4062  0.3913\n",
      "0.5909  0.4091\n",
      "0.4815  0.4000\n"
     ]
    }
   ],
   "source": [
    "corrects = 0\n",
    "wrongs = 0\n",
    "\n",
    "# format \n",
    "# yes = 0\n",
    "# no = 1\n",
    "Y_pred_yes = []\n",
    "Y_pred_no = []\n",
    "Y_test = []\n",
    "\n",
    "scientific_notation = \"{:.2e}\"\n",
    "out_trace_1 = []\n",
    "for i in range(0, len(Scores_yes)):\n",
    "    predicted = \"yes\" if Scores_yes[i] >= Scores_no[i] else \"no\"\n",
    "    actual = Y_covid_test_public[i]\n",
    "    \n",
    "    Y_pred_yes_val = 0 if Scores_yes[i] >= Scores_no[i] else 1\n",
    "    Y_pred_yes.append(Y_pred_yes_val)\n",
    "    Y_pred_no.append(1 if Y_pred_yes_val == 0 else 0)\n",
    "    Y_test.append(0 if Y_covid_test_public[i] == \"yes\" else 1)\n",
    "    \n",
    "    \n",
    "    correct = \"correct\" if predicted == actual else \"wrong\"\n",
    "    if correct == \"correct\":\n",
    "        corrects += 1\n",
    "    elif correct == \"wrong\":\n",
    "        wrongs += 1\n",
    "        \n",
    "    \n",
    "    score = max(Scores_yes[i], Scores_no[i])\n",
    "    line = f\"{X_covid_test_public_tweet_ids[i]}  {predicted}  {scientific_notation.format(score)}  {actual}  {correct}\"\n",
    "    out_trace_1.append(line)\n",
    "    \n",
    "report_yes = classification_report(Y_test, Y_pred_yes, digits=4)\n",
    "report_no = classification_report(Y_test, Y_pred_no, digits=4)\n",
    "conf = confusion_matrix(Y_test, Y_pred_yes)\n",
    "print(report_yes)\n",
    "print(report_no)\n",
    "print(conf)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred_yes)\n",
    "precision_yes = precision_score(Y_test, Y_pred_yes)\n",
    "precision_no = precision_score(Y_test, Y_pred_no)\n",
    "recall_yes = recall_score(Y_test, Y_pred_yes)\n",
    "recall_no = recall_score(Y_test, Y_pred_no)\n",
    "f1_yes = f1_score(Y_test, Y_pred_yes)\n",
    "f1_no = f1_score(Y_test, Y_pred_no)\n",
    "out_eval_1 = f\"\"\"{'{0:.4f}'.format(accuracy)}\n",
    "{'{0:.4f}'.format(precision_yes)}  {'{0:.4f}'.format(precision_no)}\n",
    "{'{0:.4f}'.format(recall_yes)}  {'{0:.4f}'.format(recall_no)}\n",
    "{'{0:.4f}'.format(f1_yes)}  {'{0:.4f}'.format(f1_no)}\"\"\"\n",
    "\n",
    "print(out_eval_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6429    0.5455    0.5902        33\n",
      "           1     0.4444    0.5455    0.4898        22\n",
      "\n",
      "    accuracy                         0.5455        55\n",
      "   macro avg     0.5437    0.5455    0.5400        55\n",
      "weighted avg     0.5635    0.5455    0.5500        55\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5556    0.4545    0.5000        33\n",
      "           1     0.3571    0.4545    0.4000        22\n",
      "\n",
      "    accuracy                         0.4545        55\n",
      "   macro avg     0.4563    0.4545    0.4500        55\n",
      "weighted avg     0.4762    0.4545    0.4600        55\n",
      "\n",
      "[[18 15]\n",
      " [10 12]]\n",
      "0.5455\n",
      "0.4444  0.3571\n",
      "0.5455  0.4545\n",
      "0.4898  0.4000\n"
     ]
    }
   ],
   "source": [
    "corrects_fv = 0\n",
    "wrongs_fv = 0\n",
    "\n",
    "# format \n",
    "# yes = 0\n",
    "# no = 1\n",
    "Y_pred_yes_fv = []\n",
    "Y_pred_no_fv = []\n",
    "\n",
    "scientific_notation = \"{:.2e}\"\n",
    "out_trace_2 = []\n",
    "for i in range(0, len(Scores_yes_fv)):\n",
    "    predicted = \"yes\" if Scores_yes_fv[i] >= Scores_no_fv[i] else \"no\"\n",
    "    actual = Y_covid_test_public[i]\n",
    "    \n",
    "    Y_pred_yes_val = 0 if Scores_yes_fv[i] >= Scores_no_fv[i] else 1\n",
    "    Y_pred_yes_fv.append(Y_pred_yes_val)\n",
    "    Y_pred_no_fv.append(1 if Y_pred_yes_val == 0 else 0)\n",
    "    \n",
    "    correct = \"correct\" if predicted == actual else \"wrong\"\n",
    "    if correct == \"correct\":\n",
    "        corrects_fv += 1\n",
    "    elif correct == \"wrong\":\n",
    "        wrongs_fv += 1\n",
    "        \n",
    "    \n",
    "    score = max(Scores_yes_fv[i], Scores_no_fv[i])\n",
    "    line = f\"{X_covid_test_public_tweet_ids[i]}  {predicted}  {scientific_notation.format(score)}  {actual}  {correct}\"\n",
    "    out_trace_2.append(line)\n",
    "    \n",
    "report_yes_fv = classification_report(Y_test, Y_pred_yes_fv, digits=4)\n",
    "report_no_fv = classification_report(Y_test, Y_pred_no_fv, digits=4)\n",
    "conf_fv = confusion_matrix(Y_test, Y_pred_yes_fv)\n",
    "print(report_yes_fv)\n",
    "print(report_no_fv)\n",
    "print(conf_fv)\n",
    "\n",
    "accuracy_fv = accuracy_score(Y_test, Y_pred_yes_fv)\n",
    "precision_yes_fv = precision_score(Y_test, Y_pred_yes_fv)\n",
    "precision_no_fv = precision_score(Y_test, Y_pred_no_fv)\n",
    "recall_yes_fv = recall_score(Y_test, Y_pred_yes_fv)\n",
    "recall_no_fv = recall_score(Y_test, Y_pred_no_fv)\n",
    "f1_yes_fv = f1_score(Y_test, Y_pred_yes_fv)\n",
    "f1_no_fv = f1_score(Y_test, Y_pred_no_fv)\n",
    "out_eval_2 = f\"\"\"{'{0:.4f}'.format(accuracy_fv)}\n",
    "{'{0:.4f}'.format(precision_yes_fv)}  {'{0:.4f}'.format(precision_no_fv)}\n",
    "{'{0:.4f}'.format(recall_yes_fv)}  {'{0:.4f}'.format(recall_no_fv)}\n",
    "{'{0:.4f}'.format(f1_yes_fv)}  {'{0:.4f}'.format(f1_no_fv)}\"\"\"\n",
    "\n",
    "print(out_eval_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True Positive TP     False Negative FN\n",
    "# False Positive FP    True Negative TN\n",
    "\n",
    "# Precision = TP / (TP + FP)\n",
    "# Recall = TP / (TP + FN)\n",
    "# Accuracy = (TP + TN) / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_1 = open(\"output_files/traceNB-BOW-OV.txt\", \"w\")\n",
    "for line in out_trace_1:\n",
    "    trace_1.write(line)\n",
    "    trace_1.write(\"\\n\")\n",
    "trace_1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_1 = open(\"output_files/evalNB-BOW-OV.txt\", \"w\")\n",
    "eval_1.write(out_eval_1)\n",
    "\n",
    "eval_1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_2 = open(\"output_files/traceNB-BOW-FV.txt\", \"w\")\n",
    "for line in out_trace_2:\n",
    "    trace_2.write(line)\n",
    "    trace_2.write(\"\\n\")\n",
    "trace_2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_2 = open(\"output_files/evalNB-BOW-FV.txt\", \"w\")\n",
    "eval_2.write(out_eval_2)\n",
    "\n",
    "eval_2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
